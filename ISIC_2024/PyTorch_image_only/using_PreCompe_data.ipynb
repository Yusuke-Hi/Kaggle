{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":8805041,"sourceType":"datasetVersion","datasetId":5295511},{"sourceId":8805074,"sourceType":"datasetVersion","datasetId":5295526},{"sourceId":8805104,"sourceType":"datasetVersion","datasetId":5295545}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Baseline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# !python -m pip install -q lightning\n# !pip install -q git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git","metadata":{"execution":{"iopub.status.busy":"2024-07-27T12:57:14.363488Z","iopub.execute_input":"2024-07-27T12:57:14.364306Z","iopub.status.idle":"2024-07-27T12:57:14.400147Z","shell.execute_reply.started":"2024-07-27T12:57:14.364249Z","shell.execute_reply":"2024-07-27T12:57:14.398745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, gc, sys, copy\nfrom pathlib import Path\nimport glob\nfrom collections import defaultdict, Counter\nfrom tqdm.auto import tqdm\ntqdm.pandas()\n\nimport random\nimport math\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, SequentialSampler\n\nimport albumentations as A\nimport timm\n\nfrom transformers import get_cosine_schedule_with_warmup\n\nimport cv2\nimport PIL\nfrom IPython import display\n\nimport tensorflow as tf\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-07-28T04:41:50.249095Z","iopub.execute_input":"2024-07-28T04:41:50.249565Z","iopub.status.idle":"2024-07-28T04:42:10.961294Z","shell.execute_reply.started":"2024-07-28T04:41:50.249528Z","shell.execute_reply":"2024-07-28T04:42:10.960065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seeding(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = False\n        torch.backends.cudnn.benchmark = True\n    print(f\"Seeding done ...\")\n    \ndef flush():\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        torch.cuda.reset_peak_memory_stats()","metadata":{"execution":{"iopub.status.busy":"2024-07-28T04:42:10.963491Z","iopub.execute_input":"2024-07-28T04:42:10.964331Z","iopub.status.idle":"2024-07-28T04:42:10.972275Z","shell.execute_reply.started":"2024-07-28T04:42:10.964286Z","shell.execute_reply":"2024-07-28T04:42:10.971044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = dict(\n    seed = 42,\n    nfolds = 5,\n    backbone = \"tf_efficientnet_b0.ns_jft_in1k\", # convnext_base.fb_in1k, \n    \n    drop_rate = 0,\n    drop_rate_last = 0.3,\n    drop_rate_path = 0.,\n    out_dim = 1,\n    batch_size = 32,\n    img_size = 224,\n    lr = 1e-3,\n    warmup = 1,\n    num_cycles = 0.475,\n    epochs = 5,\n    patience = 7,\n    log_wandb = True,\n    with_clip = False,\n    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n)\n\nif CONFIG['log_wandb']:\n    CONFIG['project_name'] = \"ISIC2024-TransferLearning\"\n    CONFIG['artifact_name'] = \"isicBaseModel\"\n    import wandb\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    secret_value_0 = user_secrets.get_secret(\"WANDB_API_KEY\")\n    wandb.login(key=secret_value_0)\n    \nseeding(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2024-07-28T04:42:10.973687Z","iopub.execute_input":"2024-07-28T04:42:10.974072Z","iopub.status.idle":"2024-07-28T04:42:13.757377Z","shell.execute_reply.started":"2024-07-28T04:42:10.974038Z","shell.execute_reply":"2024-07-28T04:42:13.756249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_PATH_2024 = Path(\"/kaggle/input/isic-2024-challenge\")\nDATA_PATH_2020 = Path(\"/kaggle/input/isic-2020-jpg-256x256-resized\")\nDATA_PATH_2019 = Path(\"/kaggle/input/isic-2019-jpg-256x256-resized\")\nDATA_PATH_2018 = Path(\"/kaggle/input/isic-2018-jpg-256x256-resized\")","metadata":{"execution":{"iopub.status.busy":"2024-07-28T04:42:13.760661Z","iopub.execute_input":"2024-07-28T04:42:13.761619Z","iopub.status.idle":"2024-07-28T04:42:13.767005Z","shell.execute_reply.started":"2024-07-28T04:42:13.761585Z","shell.execute_reply":"2024-07-28T04:42:13.765793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_2024 = pd.read_csv(DATA_PATH_2024/\"train-metadata.csv\")\ndf_train_2020 = pd.read_csv(DATA_PATH_2020/\"train-metadata.csv\")\ndf_train_2019 = pd.read_csv(DATA_PATH_2019/\"train-metadata.csv\")\ndf_train_2018 = pd.read_csv(DATA_PATH_2018/\"train-metadata.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-07-28T04:42:13.768549Z","iopub.execute_input":"2024-07-28T04:42:13.768974Z","iopub.status.idle":"2024-07-28T04:42:21.277236Z","shell.execute_reply.started":"2024-07-28T04:42:13.76893Z","shell.execute_reply":"2024-07-28T04:42:21.2762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check image paths","metadata":{}},{"cell_type":"code","source":"get_image_path_2024 = lambda p: os.path.join(f'{str(DATA_PATH_2024/\"train-image/image\")}/{p}.jpg')\nget_image_path_2020 = lambda p: os.path.join(f'{str(DATA_PATH_2020/\"train-image/image\")}/{p}.jpg')\nget_image_path_2019 = lambda p: os.path.join(f'{str(DATA_PATH_2019/\"train-image/image\")}/{p}.jpg')\nget_image_path_2018 = lambda p: os.path.join(f'{str(DATA_PATH_2018/\"train-image/image\")}/{p}.jpg')\n\ncheck_path = lambda p: tf.io.gfile.exists(p)\n\ndf_train_2024['image_path'] = df_train_2024['isic_id'].progress_apply(get_image_path_2024)\ndf_train_2020['image_path'] = df_train_2020['isic_id'].progress_apply(get_image_path_2020)\ndf_train_2019['image_path'] = df_train_2019['isic_id'].progress_apply(get_image_path_2019)\n\ndf_train_2018['image_path'] = df_train_2018['isic_id'].progress_apply(get_image_path_2018)\nprint(\"\\nChecking 2018 image files ...\")\ndf_train_2018['exists'] = df_train_2018['image_path'].progress_apply(check_path)\ndisplay.display(df_train_2018['exists'].value_counts())\ndf_train_2018 = df_train_2018[df_train_2018['exists'] == True].reset_index()","metadata":{"execution":{"iopub.status.busy":"2024-07-28T04:42:21.278573Z","iopub.execute_input":"2024-07-28T04:42:21.278902Z","iopub.status.idle":"2024-07-28T04:42:44.968014Z","shell.execute_reply.started":"2024-07-28T04:42:21.278873Z","shell.execute_reply":"2024-07-28T04:42:44.966754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_2020 = df_train_2020[df_train_2020['target'] == 1]\ntarget_2019 = df_train_2019[df_train_2019['target'] == 1]\ntarget_2018 = df_train_2018[df_train_2018['target'] == 1]\n\ncombined_data = pd.concat([df_train_2024, target_2020, target_2019, target_2018], axis=0).reset_index(drop=True)\ncombined_data = combined_data[['patient_id', 'target', 'image_path']]\n# pd.concat([extern_data] * 10)\n# extern_data = extern_data","metadata":{"execution":{"iopub.status.busy":"2024-07-28T04:42:44.969386Z","iopub.execute_input":"2024-07-28T04:42:44.96976Z","iopub.status.idle":"2024-07-28T04:42:45.665202Z","shell.execute_reply.started":"2024-07-28T04:42:44.969728Z","shell.execute_reply":"2024-07-28T04:42:45.664164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(4, 5, figsize=(7,7))\naxes = axes.flatten()\n\nfor i in range(20):\n    path = df_train_2024.loc[i, 'image_path']\n    img = PIL.Image.open(path).convert(\"RGB\")\n    axes[i].imshow(img)\n    axes[i].axis(False)\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-28T04:42:45.666545Z","iopub.execute_input":"2024-07-28T04:42:45.66693Z","iopub.status.idle":"2024-07-28T04:42:46.785284Z","shell.execute_reply.started":"2024-07-28T04:42:45.666893Z","shell.execute_reply":"2024-07-28T04:42:46.78411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of targets in the datasets","metadata":{}},{"cell_type":"code","source":"# plt.title(\"2024\")\n# df_train_2024['target'].value_counts().plot(kind='bar', figsize=(20,4));","metadata":{"execution":{"iopub.status.busy":"2024-07-28T04:42:46.786858Z","iopub.execute_input":"2024-07-28T04:42:46.787252Z","iopub.status.idle":"2024-07-28T04:42:46.792159Z","shell.execute_reply.started":"2024-07-28T04:42:46.787217Z","shell.execute_reply":"2024-07-28T04:42:46.79097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split data","metadata":{}},{"cell_type":"code","source":"kfold = model_selection.StratifiedGroupKFold(n_splits=CONFIG['nfolds'], random_state=CONFIG['seed'], shuffle=True)\ndf = combined_data.sample(frac=1, random_state=CONFIG['seed']).reset_index(drop=True)\n\ndf = df.sample(frac=1, random_state=CONFIG['seed']).reset_index(drop=True)\ndf['fold'] = -1\nx = df.index.values\ny = df.target.astype(int)\ng = df['patient_id']\n\nfor fold, (tr_idx, val_idx) in enumerate(kfold.split(x,y,g)):\n    df.loc[val_idx, 'fold'] = fold\n    \ndf.groupby('fold')['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-07-28T04:42:46.795679Z","iopub.execute_input":"2024-07-28T04:42:46.796659Z","iopub.status.idle":"2024-07-28T04:42:51.029664Z","shell.execute_reply.started":"2024-07-28T04:42:46.79662Z","shell.execute_reply":"2024-07-28T04:42:51.028494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-03T03:40:34.355615Z","iopub.execute_input":"2024-07-03T03:40:34.356054Z","iopub.status.idle":"2024-07-03T03:40:34.363626Z","shell.execute_reply.started":"2024-07-03T03:40:34.356023Z","shell.execute_reply":"2024-07-03T03:40:34.362387Z"}}},{"cell_type":"code","source":"class ISICDataset(Dataset):\n    def __init__(self, df, mode='train', transform=None, target='target'):\n        self.df = df\n        self.mode = mode\n        self.transform = transform\n        self.label = df[target]\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = row.image_path\n        target = row.target\n        \n        img = PIL.Image.open(img_path).convert(\"RGB\")\n        img = np.array(img)\n        if self.transform is not None:\n            img = self.transform(image=img)['image']\n            \n#         img = img.transpose(2, 0, 1).astype(np.float32) / 255.\n        img = img.transpose(2, 0, 1).astype(np.float32) \n        return {\"image\": torch.tensor(img).float(), \"target\": torch.tensor(target)}\n    \n    def get_labels(self):\n        return self.label\n\n# xdf = df[df['fold'] == 3].reset_index(drop=True)\n# labels = xdf['target'].astype(int)\nlabels = df['target'].astype(int)\nWEIGHTS = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels)\nWEIGHTS","metadata":{"execution":{"iopub.status.busy":"2024-07-28T04:42:51.031056Z","iopub.execute_input":"2024-07-28T04:42:51.03147Z","iopub.status.idle":"2024-07-28T04:42:51.118147Z","shell.execute_reply.started":"2024-07-28T04:42:51.031429Z","shell.execute_reply":"2024-07-28T04:42:51.116831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check distribution of labels within the batch\n\nTo avoid highly imbalanced batches, its preferable to use larger batch sizes at least 16 and above","metadata":{"execution":{"iopub.status.busy":"2024-07-03T06:12:03.238979Z","iopub.execute_input":"2024-07-03T06:12:03.239413Z","iopub.status.idle":"2024-07-03T06:12:05.841743Z","shell.execute_reply.started":"2024-07-03T06:12:03.23938Z","shell.execute_reply":"2024-07-03T06:12:05.840538Z"}}},{"cell_type":"code","source":"def check_class_distribution(dataloader):\n    for i, batch in enumerate(dataloader):\n        labels = batch['target']\n        class_dist = Counter(labels.detach().cpu().numpy())\n        if i % 500 == 1:\n            print(f\"Batch {i}\\tClass Distribution: {class_dist}\")\n        \n# dls = DataLoader(ds, batch_size=32, sampler=sampler, num_workers=os.cpu_count(), drop_last=True)\n# check_class_distribution(dls)","metadata":{"execution":{"iopub.status.busy":"2024-07-28T04:42:51.119783Z","iopub.execute_input":"2024-07-28T04:42:51.120222Z","iopub.status.idle":"2024-07-28T04:42:51.126234Z","shell.execute_reply.started":"2024-07-28T04:42:51.120181Z","shell.execute_reply":"2024-07-28T04:42:51.124949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create data loaders","metadata":{}},{"cell_type":"code","source":"def get_transforms(height, width):\n    train_tsfm = A.Compose([\n        A.Transpose(p=0.5),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.Rotate(limit=(-25, 25), p=0.5), \n        \n        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.75),\n        \n        A.OneOf([\n            A.MotionBlur(blur_limit=5),\n            A.MedianBlur(blur_limit=5),\n            A.GaussianBlur(blur_limit=5),\n            A.GaussNoise(var_limit=(5.0, 30.0))\n        ], p=0.7),\n        \n        A.OneOf([\n            A.OpticalDistortion(distort_limit=1.0),\n            A.GridDistortion(num_steps=5, distort_limit=1.0),\n            A.ElasticTransform(alpha=3),\n        ], p=0.7),\n        \n        A.CLAHE(clip_limit=4.0, p=0.7),\n        A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n        \n        A.Resize(height=height, width=width, p=1.0),\n        A.CoarseDropout(max_holes=2, max_height=int(height * 0.275), max_width=int(width * 0.275), p=0.7),\n        A.Normalize(mean=[0.485, 0.456, 0.406], \n                    std=[0.229, 0.224, 0.225], \n                    max_pixel_value=255.0, p=1)\n    ])\n    \n    valid_tsfm = A.Compose([\n        A.Resize(height=width, width=width, p=1.0),\n        A.Normalize(mean=[0.485, 0.456, 0.406], \n                    std=[0.229, 0.224, 0.225], \n                    max_pixel_value=255.0, p=1)\n    ])\n    return {\"train\": train_tsfm, \"eval\": valid_tsfm}\n\n\ndef get_dataloaders(data, cfg, split=\"train\"):\n    img_size = cfg['img_size']\n    height, width = img_size, img_size\n    tsfm = get_transforms(height=height, width=width)\n    if split == 'train':\n        tr_tsfm = tsfm['train']\n        ds = ISICDataset(data, transform=tr_tsfm)\n        labels = ds.get_labels()\n        class_weights = torch.tensor(compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels))\n        samples_weights = class_weights[labels]\n        sampler = WeightedRandomSampler(weights=samples_weights, \n                                        num_samples=len(samples_weights), \n                                        replacement=True)\n\n        dls = DataLoader(ds, \n                         batch_size=cfg['batch_size'], \n                         sampler=sampler, \n#                          shuffle=True,\n                         num_workers=os.cpu_count(), \n                         pin_memory=True, \n                         drop_last=True)\n        \n    elif split == 'valid' or split == 'test':\n        eval_tsfm = tsfm['eval']\n        ds = ISICDataset(data, transform=eval_tsfm)\n        dls = DataLoader(ds, \n                         batch_size=2*cfg['batch_size'], \n                         shuffle=False,\n                         num_workers=os.cpu_count(), \n                         pin_memory=True,\n                         drop_last=False)\n    else:\n        raise Exception(\"Split should be 'train' or 'valid' or 'test'!!!\")\n    return dls","metadata":{"execution":{"iopub.status.busy":"2024-07-28T05:07:27.154666Z","iopub.execute_input":"2024-07-28T05:07:27.155114Z","iopub.status.idle":"2024-07-28T05:07:27.17265Z","shell.execute_reply.started":"2024-07-28T05:07:27.155067Z","shell.execute_reply":"2024-07-28T05:07:27.171308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls = get_dataloaders(df, CONFIG, split='train')\n# check_class_distribution(dls)\n\nb = next(iter(dls))\n\nfig, axes = plt.subplots(4, 8, figsize=(10,10))\naxes = axes.flatten()\nimages = b['image'].detach().cpu().numpy().transpose(0, 2, 3, 1)\ntargets = b['target'].detach().cpu().numpy()\nfor i in range(32):\n    axes[i].imshow(images[i, ...])\n    axes[i].set_title(f\"{targets[i]}\")\n    axes[i].axis(False)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-28T05:07:35.366268Z","iopub.execute_input":"2024-07-28T05:07:35.366744Z","iopub.status.idle":"2024-07-28T05:07:42.202142Z","shell.execute_reply.started":"2024-07-28T05:07:35.366708Z","shell.execute_reply":"2024-07-28T05:07:42.201002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model setup","metadata":{"execution":{"iopub.status.busy":"2024-07-03T06:43:38.154777Z","iopub.execute_input":"2024-07-03T06:43:38.155202Z","iopub.status.idle":"2024-07-03T06:43:38.626251Z","shell.execute_reply.started":"2024-07-03T06:43:38.155166Z","shell.execute_reply":"2024-07-03T06:43:38.624846Z"}}},{"cell_type":"code","source":"class ISICModel(nn.Module):\n    def __init__(self, backbone, pretrained=False):\n        super(ISICModel, self).__init__()\n        self.encoder = timm.create_model(\n            backbone,\n            features_only=False,\n            drop_rate=CONFIG['drop_rate'],\n            drop_path_rate=CONFIG['drop_rate_path'],\n            pretrained=pretrained,\n        )\n        \n        self.nb_fts = self.encoder.num_features\n        self.gap = nn.AdaptiveAvgPool2d(1)\n        self.lstm = nn.LSTM(self.nb_fts, 256, num_layers=2, dropout=CONFIG[\"drop_rate\"], bidirectional=True, batch_first=True)\n        self.head = nn.Sequential(\n                        nn.Linear(512, 256),\n                        nn.BatchNorm1d(256),\n                        nn.Dropout(CONFIG[\"drop_rate_last\"]),\n                        nn.LeakyReLU(0.1),\n                        nn.Linear(256, 1),\n                    )\n        \n    def forward(self, x):\n        feat = self.encoder.forward_features(x)\n        feat = self.gap(feat)[:,:,0,0]\n        feat, _ = self.lstm(feat)\n        y = self.head(feat)\n        \n        return y\n    \n    def freeze_encoder(self, flag):\n        for param in self.encoder.parameters():\n            param.requires_grad = not flag\n            \n# net = ISICModel('resnet18')\n# x = torch.rand(8, 3, 224, 224)\n# net.eval()\n# net(x)","metadata":{"execution":{"iopub.status.busy":"2024-07-28T00:54:38.844665Z","iopub.execute_input":"2024-07-28T00:54:38.84564Z","iopub.status.idle":"2024-07-28T00:54:38.855276Z","shell.execute_reply.started":"2024-07-28T00:54:38.8456Z","shell.execute_reply":"2024-07-28T00:54:38.854088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Weighted Binary Cross Entropy lossess\n\nConsidering that the data is heavily imbalanced, it's definitely, a good practice to use a weighted loss for this task\n\nFor binary classification imbalanced dataset, always consider positive values to the minority class and negative values to the majority class [how-can-i-know-which-is-the-positive-class-value-and-negative-class-value](https://stackoverflow.com/questions/65304302/how-can-i-know-which-is-the-positive-class-value-and-negative-class-value-for-xg)\n\nBased on 2024 dataset, there is a **very small fraction of positive samples (malignant)** with ratio of `0.5:510`.\n\nAfter adding the external data, we get a ratio of `0.5:33` \n\nMore information regarding how to deal with class imbalance can be found here [imbalanced_data](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data), [class-imbalance-weighted-binary-cross-entropy](https://www.kaggle.com/code/parthdhameliya77/class-imbalance-weighted-binary-cross-entropy)","metadata":{}},{"cell_type":"markdown","source":"# Training with pytorch lightning","metadata":{}},{"cell_type":"code","source":"# def get_scheduler(optimizer, warmup=True):\n#     if warmup:\n#         scheduler = get_cosine_schedule_with_warmup(\n#                 optimizer,\n#                 num_warmup_steps=CONFIG[\"warmup\"] * (CONFIG['n_steps_per_epoch']),\n#                 num_training_steps=CONFIG[\"epochs\"]* (CONFIG['n_steps_per_epoch']),\n#                 num_cycles = CONFIG[\"num_cycles\"],\n#             )\n#     else:\n#         scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG[\"epochs\"], eta_min=0)\n#     return scheduler","metadata":{"execution":{"iopub.status.busy":"2024-07-27T12:58:34.90299Z","iopub.execute_input":"2024-07-27T12:58:34.904068Z","iopub.status.idle":"2024-07-27T12:58:34.920662Z","shell.execute_reply.started":"2024-07-27T12:58:34.904018Z","shell.execute_reply":"2024-07-27T12:58:34.919144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class ISICLightningModel(pl.LightningModule):\n#     def __init__(self, pretrained=False):\n#         super().__init__()\n#         self.model = ISICModel(CONFIG['backbone'], pretrained=pretrained)\n# #         print(WEIGHTS[1])\n#         self.loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(WEIGHTS[1]))\n    \n#     def forward(self, image):\n#         return self.model(image)\n    \n#     def shared_step(self, batch, stage):\n#         images, labels = batch['image'], batch['target']\n#         logits = self.forward(images)\n#         loss = self.loss_fn(logits.squeeze(), labels)\n#         preds = logits.sigmoid()\n#         self.log(f\"{stage}_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n        \n#         outputs = {\n#             \"loss\": loss,\n#             \"preds\": preds\n#         }\n#         return outputs\n    \n    \n#     def training_step(self, batch, batch_idx):\n#         return self.shared_step(batch, stage='train')\n    \n#     def validation_step(self, batch, batch_idx):\n#         return self.shared_step(batch, stage='valid')\n    \n#     def configure_optimizers(self):\n#         optimizer = torch.optim.AdamW(self.parameters(), lr=CONFIG['lr'])\n#         after_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG[\"epochs\"], eta_min=0)\n#         scheduler = GradualWarmupScheduler(optimizer, multiplier=1, \n#                                            total_epoch=math.ceil(CONFIG[\"warmup\"]*CONFIG['epochs']), \n#                                            after_scheduler=after_scheduler)\n# #         scheduler = get_scheduler(optimizer)\n#         return [optimizer], [scheduler]","metadata":{"execution":{"iopub.status.busy":"2024-07-27T12:58:34.922301Z","iopub.execute_input":"2024-07-27T12:58:34.92276Z","iopub.status.idle":"2024-07-27T12:58:34.936791Z","shell.execute_reply.started":"2024-07-27T12:58:34.922711Z","shell.execute_reply":"2024-07-27T12:58:34.935431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for fold in range(5):\n#     train_ds = df[df['fold'] != fold].reset_index(drop=True)\n#     valid_ds = df[df['fold'] == fold].reset_index(drop=True)\n    \n#     train_loader = get_dataloaders(train_ds, CONFIG, split=\"train\")\n#     valid_loader = get_dataloaders(valid_ds, CONFIG, split=\"valid\")\n#     n_steps_per_epoch = math.ceil(len(train_loader.dataset) / CONFIG['batch_size'])\n#     CONFIG['n_steps_per_epoch'] = n_steps_per_epoch\n    \n#     if CONFIG['log_wandb']:\n#         wandb_logger = WandbLogger(\n#             project=CONFIG[\"project_name\"],\n#             checkpoint_name=f'{CONFIG[\"artifact_name\"]}_{fold}',\n#             log_model=\"all\",\n#         )\n        \n#     logger = wandb_logger if CONFIG['log_wandb'] else None\n\n#     callbacks = [\n#         ModelCheckpoint(save_weights_only=True, \n#                         mode=\"min\", \n#                         monitor=\"valid_loss\"),\n#         LearningRateMonitor(\"epoch\"),\n#     ]\n    \n#     net = ISICLightningModel(pretrained=True)\n    \n#     trainer = pl.Trainer(accelerator=\"gpu\", devices=1, \n#                          precision=\"16-mixed\",\n#                          max_epochs=CONFIG['epochs'], \n#                          logger=logger, callbacks=callbacks, default_root_dir=os.getcwd())\n    \n#     trainer.fit(net, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n#     break\n    \n    \n# if CONFIG['log_wandb']:\n#     wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-07-27T12:58:34.938685Z","iopub.execute_input":"2024-07-27T12:58:34.939137Z","iopub.status.idle":"2024-07-27T12:58:34.954542Z","shell.execute_reply.started":"2024-07-27T12:58:34.939102Z","shell.execute_reply":"2024-07-27T12:58:34.953285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# timm.list_pretrained(\"resnet*\")","metadata":{"execution":{"iopub.status.busy":"2024-07-28T00:55:15.81584Z","iopub.execute_input":"2024-07-28T00:55:15.816272Z","iopub.status.idle":"2024-07-28T00:55:15.82185Z","shell.execute_reply.started":"2024-07-28T00:55:15.816222Z","shell.execute_reply":"2024-07-28T00:55:15.820691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pytorch training","metadata":{}},{"cell_type":"code","source":"class MetricMonitor:\n    def __init__(self, float_precision=4):\n        self.float_precision = float_precision\n        self.reset()\n\n    def reset(self):\n        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n\n    def update(self, metric_name, val):\n        metric = self.metrics[metric_name]\n\n        metric[\"val\"] += val\n        metric[\"count\"] += 1\n        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n\n    def __str__(self):\n        return \" | \".join(\n            [\n                \"{metric_name}: {avg:.{float_precision}f}\".format(\n                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n                )\n                for (metric_name, metric) in self.metrics.items()\n            ]\n        )\n    \n    \n# def get_auc(y_true, y_preds, weights=None):\n#     return metrics.roc_auc_score(y_true, y_preds, max_fpr=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-07-28T00:56:10.393515Z","iopub.execute_input":"2024-07-28T00:56:10.393949Z","iopub.status.idle":"2024-07-28T00:56:10.402234Z","shell.execute_reply.started":"2024-07-28T00:56:10.393916Z","shell.execute_reply":"2024-07-28T00:56:10.400852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training functions","metadata":{}},{"cell_type":"code","source":"def init_weights(m):\n    if type(m) == nn.Linear:\n        torch.nn.init.xavier_uniform(m.weight)\n        m.bias.data.fill_(0.01)\n\ndef shared_step(model, batch, criterion):\n    image, target = batch['image'], batch['target']\n    image = image.to(CONFIG[\"device\"], non_blocking=True)\n    target = target.to(CONFIG[\"device\"], non_blocking=True)\n    outputs = model(image)\n    loss = criterion(outputs.squeeze(), target.to(torch.float64))\n    logits = outputs.sigmoid()\n    \n\n    return {\n        \"loss\": loss,\n        \"labels\": target,\n        \"logits\": logits,\n    }\n\n# output = shared_step(net, b, criterion)\ndef train(train_loader, model, criterion, optimizer, epoch, scaler, scheduler):\n    metric_monitor = MetricMonitor()\n    model.train()\n    stream = tqdm(train_loader)\n    train_loss = 0\n    for i, batch in enumerate(stream, start=1):\n        optimizer.zero_grad(set_to_none=True)\n        \n        with torch.autocast(device_type='cuda', dtype=torch.float16):\n            outputs = shared_step(model, batch, criterion)\n            loss =  outputs['loss']\n        \n        metric_monitor.update(\"Loss\", loss)\n        train_loss += loss.detach().float()\n        CONFIG['example_ct'] += len(batch[\"image\"])\n        # backward pass, with gradient scaling\n        scaler.scale(loss).backward()\n        \n        # clip the gradient\n        if CONFIG['with_clip']:\n            scaler.unscale_(optimizer)\n            nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n        \n        lr = optimizer.param_groups[0]['lr']\n        scaler.step(optimizer)\n        scaler.update()\n        \n        _train_metrics = {\n            \"train/step_loss\": loss,\n            \"train/epoch\": (i + 1 + CONFIG['n_steps_per_epoch'] * CONFIG['epochs']),\n            \"train/example_ct\": CONFIG['example_ct'],\n            \"lr\": lr,\n        }\n        \n        if CONFIG['log_wandb'] and (i+1 < CONFIG['n_steps_per_epoch']):\n            wandb.log(_train_metrics)\n        \n        CONFIG['step_ct'] += 1\n        if scheduler is not None:\n            scheduler.step()\n        \n        stream.set_description(\n            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n        )\n        \n    total_train_loss = train_loss / len(train_loader)\n    _train_metrics['train/epoch_loss'] = total_train_loss\n    \n    flush()\n    return _train_metrics\n\n\ndef validate(val_loader, model, criterion, epoch):\n    metric_monitor = MetricMonitor()\n    model.eval()\n    stream = tqdm(val_loader)\n    valid_loss = 0\n    \n    with torch.no_grad():\n        for i, batch in enumerate(stream, start=1):\n            with torch.autocast(device_type='cuda', dtype=torch.float16):\n                outputs = shared_step(model, batch, criterion)\n                loss =  outputs['loss']\n\n            metric_monitor.update(\"Loss\", loss)\n            valid_loss += loss.detach().float()\n            _valid_metrics = {\n                    \"valid/step_loss\": loss,\n                }\n            \n            if CONFIG['log_wandb']:\n                wandb.log(_valid_metrics)\n            \n            stream.set_description(\n                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n            )\n            \n    total_valid_loss = valid_loss / len(val_loader)\n    _valid_metrics['valid/epoch_loss'] = total_valid_loss\n    flush()\n    return _valid_metrics","metadata":{"execution":{"iopub.status.busy":"2024-07-28T00:56:11.18487Z","iopub.execute_input":"2024-07-28T00:56:11.185323Z","iopub.status.idle":"2024-07-28T00:56:11.204219Z","shell.execute_reply.started":"2024-07-28T00:56:11.18525Z","shell.execute_reply":"2024-07-28T00:56:11.20312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_and_validate(model, train_dataset, val_dataset, fold=0):\n    if CONFIG['log_wandb']:\n        run = wandb.init(\n            project=CONFIG[\"project_name\"],\n            resume=\"allow\",\n        )\n        artifact = wandb.Artifact(f\"{CONFIG['artifact_name']}_{fold}\", type=\"model\")\n    \n    if torch.cuda.is_available():\n        if torch.cuda.device_count() > 1:\n            DEVICE_IDS = list(range(torch.cuda.device_count()))\n            print(f\"\\nUsing {len(DEVICE_IDS)} GPUs to train ...\\n\")\n            model = nn.DataParallel(model, device_ids=DEVICE_IDS)\n            \n    model = model.to(CONFIG[\"device\"])\n#     model.apply(init_weights)\n    train_loader = get_dataloaders(train_dataset, CONFIG, split=\"train\")\n    valid_loader = get_dataloaders(val_dataset, CONFIG, split=\"valid\")\n    \n    n_steps_per_epoch = math.ceil(len(train_loader.dataset) / CONFIG['batch_size'])\n    CONFIG['n_steps_per_epoch'] = n_steps_per_epoch\n    CONFIG['example_ct'] = 0\n    CONFIG['step_ct'] = 0\n    \n    total_steps = len(train_loader)\n#     criterion = nn.BCEWithLogitsLoss()\n    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(WEIGHTS[1]))\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG[\"lr\"])\n    scaler = torch.cuda.amp.GradScaler()\n\n    scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=CONFIG[\"warmup\"] * CONFIG['n_steps_per_epoch'],\n            num_training_steps=CONFIG[\"epochs\"]* CONFIG['n_steps_per_epoch'],\n            num_cycles = CONFIG[\"num_cycles\"],\n        )\n    \n    best_metric = np.inf\n    loss_min = np.inf\n    es = 0\n    ES_RATIO = 0.3 if CONFIG[\"epochs\"] < 30 else 0.20\n    weights_file = \"ISIC_2024_fold_{fold}_epoch_{epoch}.pth\"\n    for epoch in range(1, CONFIG[\"epochs\"] + 1):\n        _train_metrics = train(train_loader, model, criterion, optimizer, epoch, scaler, scheduler=scheduler)\n        _valid_metrics = validate(valid_loader, model, criterion, epoch)\n        \n        val_loss = _valid_metrics['valid/epoch_loss']\n        if CONFIG['log_wandb']:\n            wandb.log({**_train_metrics, **_valid_metrics})\n        \n        if val_loss < best_metric:\n            print(f\"Best metric: ({best_metric:.6f} --> {val_loss:.6f}). Saving model ...\")\n            if torch.cuda.device_count() > 2:\n                torch.save(model.module.state_dict(), weights_file.format(fold=fold, epoch=epoch))\n            else:\n                torch.save(model.state_dict(), weights_file.format(fold=fold, epoch=epoch))\n            best_metric = val_loss\n            if CONFIG['log_wandb']:\n                if epoch == 1:\n                    artifact.add_file(weights_file.format(fold=fold, epoch=epoch))\n                    run.log_artifact(artifact)\n                else:\n                    draft_artifact = wandb.Artifact(f\"{CONFIG['artifact_name']}_{fold}\", type=\"model\")\n                    draft_artifact.add_file(weights_file.format(fold=fold, epoch=epoch))\n                    run.log_artifact(draft_artifact)\n                \n            es = 0\n            \n        else:\n            es += 1\n            \n        if es > math.ceil(ES_RATIO*CONFIG[\"epochs\"]):\n            print(f\"Early stopping on epoch {epoch} ...\")\n            break\n    \n    if CONFIG['log_wandb']:\n        wandb.config = CONFIG\n        wandb.finish()\n        \n    del model, train_loader, valid_loader\n    flush()","metadata":{"execution":{"iopub.status.busy":"2024-07-28T00:56:12.396067Z","iopub.execute_input":"2024-07-28T00:56:12.396486Z","iopub.status.idle":"2024-07-28T00:56:12.415799Z","shell.execute_reply.started":"2024-07-28T00:56:12.396452Z","shell.execute_reply":"2024-07-28T00:56:12.414344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"for fold in range(5):\n    model = ISICModel(backbone=CONFIG[\"backbone\"], pretrained=True)\n#     model.freeze_encoder(False)\n    train_ds = df[df['fold'] != fold].reset_index(drop=True)\n    valid_ds = df[df['fold'] == fold].reset_index(drop=True)\n#     valid_ds = pd.concat([valid_ds, extern_data]).sample(frac=1.0, random_state=CONFIG['seed']).reset_index(drop=True)\n    train_and_validate(model, train_ds, valid_ds, fold=fold)\n    \n    break\ngc.collect()\nflush()","metadata":{"execution":{"iopub.status.busy":"2024-07-28T00:56:16.223886Z","iopub.execute_input":"2024-07-28T00:56:16.224337Z","iopub.status.idle":"2024-07-28T00:56:42.558843Z","shell.execute_reply.started":"2024-07-28T00:56:16.224273Z","shell.execute_reply":"2024-07-28T00:56:42.556854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}