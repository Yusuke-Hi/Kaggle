{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":8982084,"sourceType":"datasetVersion","datasetId":5406640},{"sourceId":8991790,"sourceType":"datasetVersion","datasetId":5415918},{"sourceId":186147615,"sourceType":"kernelVersion"},{"sourceId":187730674,"sourceType":"kernelVersion"},{"sourceId":188543089,"sourceType":"kernelVersion"},{"sourceId":188543756,"sourceType":"kernelVersion"},{"sourceId":188602899,"sourceType":"kernelVersion"},{"sourceId":188603204,"sourceType":"kernelVersion"},{"sourceId":190801726,"sourceType":"kernelVersion"},{"sourceId":190815443,"sourceType":"kernelVersion"},{"sourceId":190817588,"sourceType":"kernelVersion"}],"dockerImageVersionId":30747,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":1375.57068,"end_time":"2024-07-20T23:48:41.494367","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-20T23:25:45.923687","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"https://www.kaggle.com/code/vyacheslavbolotin/feature-engineering-tabular-data-image-data","metadata":{}},{"cell_type":"markdown","source":"## This notebook is based on the works:","metadata":{}},{"cell_type":"markdown","source":"1) **[Naive LightGBM](https://www.kaggle.com/code/bguberfain/naive-lightgbm)** by master [*Bruno G. do Amaral*](https://www.kaggle.com/bguberfain)\n\n\n2) **[Tabular Ensemble: LGBM+Catboost](https://www.kaggle.com/code/snnclsr/tabular-ensemble-lgbm-catboost)** by master [*Sinan Calisir*](https://www.kaggle.com/snnclsr)\n\n\n3) **[ISIC 2024 Skin Cancer - Getting Started](https://www.kaggle.com/code/coderinunderpants/isic-2024-skin-cancer-getting-started)** by contributor [*Joy Banikl*](https://www.kaggle.com/coderinunderpants)\n\n\n4) **[ISIC: Tabular model + Image model features](https://www.kaggle.com/code/motono0223/isic-tabular-model-image-model-features)** by master [*motono0223*](https://www.kaggle.com/motono0223)\n\n\n5) **[Only Tabular Features: XGB+CATB+LGBM Ensemble](https://www.kaggle.com/code/rzatemizel/only-tabular-features-xgb-catb-lgbm-ensemble)** by master [*rıza temizel*](https://www.kaggle.com/rzatemizel)\n\n\n7) **[Tabular Ensemble: LGBM + Catboost | Add EdgeNext](https://www.kaggle.com/code/hugowjd/tabular-ensemble-lgbm-catboost-add-edgenext)** by expert [*Jiadi Wang*](https://www.kaggle.com/hugowjd)\n\n\n8) **[ISIC 2024 | Only Tabular Data](https://www.kaggle.com/code/greysky/isic-2024-only-tabular-data)** by master [*Farukcan Saglam*](https://www.kaggle.com/greysky)\n\n\n9) **[LGBM - CAT Ensemble --> ISIC](https://www.kaggle.com/code/abdmental01/lgbm-cat-ensemble-isic)** by grandmaster [*Sheikh Muhammad Abdullah*](https://www.kaggle.com/abdmental01)\n\n\n10) **[ISIC - Detect Skin Cancer - Let's Learn Together](https://www.kaggle.com/code/dschettler8845/isic-detect-skin-cancer-let-s-learn-together)** by grandmaster [*Darien Schettler*](https://www.kaggle.com/dschettler8845)\n\n\n11) **[ISIC 2024 Skin Cancer Detection hdf5](https://www.kaggle.com/code/mpwolke/isic-2024-skin-cancer-detection-hdf5)** by grandmaster [*Marília Prata*](https://www.kaggle.com/mpwolke)\n\n\n12) **[AI in Dermoscopy. ADAE algorithm.](https://www.kaggle.com/competitions/isic-2024-challenge/discussion/515369)** by grandmaster [*Marília Prata*](https://www.kaggle.com/mpwolke)\n","metadata":{}},{"cell_type":"markdown","source":"## [Master](https://www.kaggle.com/greysky) [work](https://www.kaggle.com/code/greysky/isic-2024-only-tabular-data):\n","metadata":{}},{"cell_type":"code","source":"import os\n\nfrom pathlib import Path\n\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.model_selection import StratifiedGroupKFold\n\nimport numpy as np, pandas as pd, polars as pl\n\nimport optuna, lightgbm as lgb, catboost as cb, xgboost as xgb","metadata":{"papermill":{"duration":6.257337,"end_time":"2024-07-20T23:25:54.992469","exception":false,"start_time":"2024-07-20T23:25:48.735132","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-07T15:11:54.710162Z","iopub.execute_input":"2024-08-07T15:11:54.710879Z","iopub.status.idle":"2024-08-07T15:12:00.510951Z","shell.execute_reply.started":"2024-08-07T15:11:54.710842Z","shell.execute_reply":"2024-08-07T15:12:00.509906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root = Path('/kaggle/input/isic-2024-challenge')\n\ntrain_path = root / 'train-metadata.csv'\ntest_path  = root / 'test-metadata.csv'\nsubm_path  = root / 'sample_submission.csv'\n\nid_col     = 'isic_id'\ngroup_col  = 'patient_id'\ntarget_col = 'target'\n\nerr = 1e-5\nsampling_ratio = 0.01\nseed = 42","metadata":{"execution":{"iopub.status.busy":"2024-08-07T15:12:03.449432Z","iopub.execute_input":"2024-08-07T15:12:03.450134Z","iopub.status.idle":"2024-08-07T15:12:03.456355Z","shell.execute_reply.started":"2024-08-07T15:12:03.450098Z","shell.execute_reply":"2024-08-07T15:12:03.455162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_cols = [\n    'age_approx',                        # Approximate age of patient at time of imaging.\n    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n    'tbp_lv_A',                          # A inside  lesion.+\n    'tbp_lv_Aext',                       # A outside lesion.+\n    'tbp_lv_B',                          # B inside  lesion.+\n    'tbp_lv_Bext',                       # B outside lesion.+ \n    'tbp_lv_C',                          # Chroma inside  lesion.+\n    'tbp_lv_Cext',                       # Chroma outside lesion.+\n    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n    'tbp_lv_Hext',                       # Hue outside lesion.+\n    'tbp_lv_L',                          # L inside lesion.+\n    'tbp_lv_Lext',                       # L outside lesion.+\n    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaLB',                    #\n    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n    'tbp_lv_eccentricity',               # Eccentricity.+\n    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n]\n\nnew_num_cols = [\n    'lesion_size_ratio',                 # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n    'lesion_shape_index',                # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n    'hue_contrast',                      # tbp_lv_H                - tbp_lv_Hext              abs\n    'luminance_contrast',                # tbp_lv_L                - tbp_lv_Lext              abs\n    'lesion_color_difference',           # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n    'border_complexity',                 # tbp_lv_norm_border      + tbp_lv_symm_2axis\n    'color_uniformity',                  # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n\n    'position_distance_3d',              # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n    'perimeter_to_area_ratio',           # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n    'area_to_perimeter_ratio',           # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n    'lesion_visibility_score',           # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n    'symmetry_border_consistency',       # tbp_lv_symm_2axis       * tbp_lv_norm_border\n    'consistency_symmetry_border',       # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n\n    'color_consistency',                 # tbp_lv_stdL             / tbp_lv_Lext\n    'consistency_color',                 # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n    'size_age_interaction',              # clin_size_long_diam_mm  * age_approx\n    'hue_color_std_interaction',         # tbp_lv_H                * tbp_lv_color_std_mean\n    'lesion_severity_index',             # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n    'shape_complexity_index',            # border_complexity       + lesion_shape_index\n    'color_contrast_index',              # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n\n    'log_lesion_area',                   # tbp_lv_areaMM2          + 1  np.log\n    'normalized_lesion_size',            # clin_size_long_diam_mm  / age_approx\n    'mean_hue_difference',               # tbp_lv_H                + tbp_lv_Hext    / 2\n    'std_dev_contrast',                  # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n    'color_shape_composite_index',       # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n    'lesion_orientation_3d',             # tbp_lv_y                , tbp_lv_x  np.arctan2\n    'overall_color_difference',          # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n\n    'symmetry_perimeter_interaction',    # tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n    'comprehensive_lesion_index',        # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n    'color_variance_ratio',              # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n    'border_color_interaction',          # tbp_lv_norm_border      * tbp_lv_norm_color\n    'border_color_interaction_2',\n    'size_color_contrast_ratio',         # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n    'age_normalized_nevi_confidence',    # tbp_lv_nevi_confidence  / age_approx\n    'age_normalized_nevi_confidence_2',\n    'color_asymmetry_index',             # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n\n    'volume_approximation_3d',           # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n    'color_range',                       # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n    'shape_color_consistency',           # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n    'border_length_ratio',               # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n    'age_size_symmetry_index',           # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n    'index_age_size_symmetry',           # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n]\n\ncat_cols = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'attribution']\nnorm_cols = [f'{col}_patient_norm' for col in num_cols + new_num_cols]\nspecial_cols = ['count_per_patient']\nfeature_cols = num_cols + new_num_cols + cat_cols + norm_cols + special_cols # + _ll_lines","metadata":{"execution":{"iopub.status.busy":"2024-08-07T15:12:06.584943Z","iopub.execute_input":"2024-08-07T15:12:06.585321Z","iopub.status.idle":"2024-08-07T15:12:06.601588Z","shell.execute_reply.started":"2024-08-07T15:12:06.585293Z","shell.execute_reply":"2024-08-07T15:12:06.600335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_data(path):\n    return (\n        pl.read_csv(path)\n        .with_columns(\n            pl.col('age_approx').cast(pl.String).replace('NA', np.nan).cast(pl.Float64),\n        )\n        .with_columns(\n            lesion_size_ratio              = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n            lesion_shape_index             = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n            hue_contrast                   =(pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n            luminance_contrast             =(pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n            lesion_color_difference        =(pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n            border_complexity              = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n            color_uniformity               = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n        )\n        .with_columns(\n            position_distance_3d           = (pl.col('tbp_lv_x') ** 2 + pl.col('tbp_lv_y') ** 2 + pl.col('tbp_lv_z') ** 2).sqrt(),\n            perimeter_to_area_ratio        = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n            area_to_perimeter_ratio        = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n            lesion_visibility_score        = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n            combined_anatomical_site       = pl.col('anatom_site_general') + '_' + pl.col('tbp_lv_location'),\n            symmetry_border_consistency    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n            consistency_symmetry_border    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n        )\n        .with_columns(\n            color_consistency              = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n            consistency_color              = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n            size_age_interaction           = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n            hue_color_std_interaction      = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n            lesion_severity_index          =(pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n            shape_complexity_index         = pl.col('border_complexity') + pl.col('lesion_shape_index'),\n            color_contrast_index           = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n        )\n        .with_columns(\n            log_lesion_area                = (pl.col('tbp_lv_areaMM2') + 1).log(),\n            normalized_lesion_size         = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n            mean_hue_difference            = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n            std_dev_contrast               = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n            color_shape_composite_index    = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n            lesion_orientation_3d          = pl.arctan2(pl.col('tbp_lv_y'), pl.col('tbp_lv_x')),\n            overall_color_difference       = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n        )\n        .with_columns(\n            symmetry_perimeter_interaction = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n            comprehensive_lesion_index     = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n            color_variance_ratio           = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n            border_color_interaction       = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n            border_color_interaction_2     = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n            size_color_contrast_ratio      = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n            age_normalized_nevi_confidence = pl.col('tbp_lv_nevi_confidence') / pl.col('age_approx'),\n            age_normalized_nevi_confidence_2 = (pl.col('clin_size_long_diam_mm')**2 + pl.col('age_approx')**2).sqrt(),\n            color_asymmetry_index          = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            volume_approximation_3d        = pl.col('tbp_lv_areaMM2') * (pl.col('tbp_lv_x')**2 + pl.col('tbp_lv_y')**2 + pl.col('tbp_lv_z')**2).sqrt(),\n            color_range                    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n            shape_color_consistency        = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n            border_length_ratio            = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n            age_size_symmetry_index        = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n            index_age_size_symmetry        = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            ((pl.col(col) - pl.col(col).mean().over('patient_id')) / (pl.col(col).std().over('patient_id') + err)).alias(f'{col}_patient_norm') for col in (num_cols + new_num_cols)\n        )\n        .with_columns(\n            count_per_patient = pl.col('isic_id').count().over('patient_id'),\n        )\n        .with_columns(\n            pl.col(cat_cols).cast(pl.Categorical),\n        )\n        .to_pandas()\n        .set_index(id_col)\n    )","metadata":{"execution":{"iopub.status.busy":"2024-08-07T15:12:35.064559Z","iopub.execute_input":"2024-08-07T15:12:35.064975Z","iopub.status.idle":"2024-08-07T15:12:35.095254Z","shell.execute_reply.started":"2024-08-07T15:12:35.064942Z","shell.execute_reply":"2024-08-07T15:12:35.093865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(df_train, df_test):\n    global cat_cols\n    \n    encoder = OneHotEncoder(sparse_output=False, dtype=np.int32, handle_unknown='ignore')\n    encoder.fit(df_train[cat_cols])\n    \n    new_cat_cols = [f'onehot_{i}' for i in range(len(encoder.get_feature_names_out()))]\n\n    df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n    df_train[new_cat_cols] = df_train[new_cat_cols].astype('category')\n\n    df_test[new_cat_cols] = encoder.transform(df_test[cat_cols])\n    df_test[new_cat_cols] = df_test[new_cat_cols].astype('category')\n\n    for col in cat_cols:\n        feature_cols.remove(col)\n\n    feature_cols.extend(new_cat_cols)\n    cat_cols = new_cat_cols\n    \n    return df_train, df_test","metadata":{"execution":{"iopub.status.busy":"2024-08-07T15:12:35.271485Z","iopub.execute_input":"2024-08-07T15:12:35.27197Z","iopub.status.idle":"2024-08-07T15:12:35.279888Z","shell.execute_reply.started":"2024-08-07T15:12:35.271937Z","shell.execute_reply":"2024-08-07T15:12:35.278625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # We delete, for now in random order, some columns of train_cols in the amount of _N_todel_cols\n\n# _N_cols_todel = random.choice([2,3,4])\n\n# _random_cols_todel = list(set(_new_num_cols[random.choice(range(len(_new_num_cols)-1))] for i in range(_N_cols_todel)))\n\n# for one_random_Col in _random_cols_todel:\n#     if one_random_Col not in _ll_line_cols: train_cols.remove(one_random_Col)\n        \n# # and let's see what happens,\n# # more precisely on the difference between what we had before and what happened after deleting\n# # 1) in our position in our leaderboard +\n# # 2) the impact of the assessment already without deleted columns using the 'function'..\n# # 3) originals: CatBoost Feature Importances + LGBM Feature Importances\n# # 4) to be continued..\n# # DISPLAY_FEATURE_IMPORTANCE = True\n# # DISPLAY_FEATURE_IMPORTANCE_LightGBM = True\n# # DISPLAY_FEATURE_IMPORTANCE_CatBoost = True\n# # DISPLAY_FEATURE_IMPORTANCE_XGBoost  = True\n# # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\n# i = 0\n# for train_col in train_cols:\n#     print(f'column {i}: {train_col}')\n#     i += 1\n# print('\\n')\n# for col_todel in _random_cols_todel: print(f'deleted: {col_todel}')\n\n# in the end, for now we will have to compare Feature Importances by viewing two files,\n# i.e. the previous version and the version with the removed columns, \n# and then adding different automated tools for this procedure\n# we will see and understand which columns are unnecessary and remove them\n# well, let's try, we'll run it several times","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_metric(estimator, X, y_true):\n    y_hat = estimator.predict_proba(X)[:, 1]\n    min_tpr = 0.80\n    max_fpr = abs(1 - min_tpr)\n    \n    v_gt = abs(y_true - 1)\n    v_pred = np.array([1.0 - x for x in y_hat])\n    \n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    \n    return partial_auc","metadata":{"execution":{"iopub.status.busy":"2024-08-07T15:12:40.82182Z","iopub.execute_input":"2024-08-07T15:12:40.82253Z","iopub.status.idle":"2024-08-07T15:12:40.829522Z","shell.execute_reply.started":"2024-08-07T15:12:40.822495Z","shell.execute_reply":"2024-08-07T15:12:40.828469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Read & Feature Engineering","metadata":{}},{"cell_type":"code","source":"df_train = read_data(train_path)\ndf_test = read_data(test_path)\ndf_subm = pd.read_csv(subm_path, index_col=id_col)\n\ndf_train, df_test = preprocess(df_train, df_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T15:12:45.081483Z","iopub.execute_input":"2024-08-07T15:12:45.082314Z","iopub.status.idle":"2024-08-07T15:12:51.697535Z","shell.execute_reply.started":"2024-08-07T15:12:45.082279Z","shell.execute_reply":"2024-08-07T15:12:51.696458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Connecting parallel image lines","metadata":{}},{"cell_type":"code","source":"# motono0223 1\n# !python /kaggle/input/isic-script-inference-eva02/main.py /kaggle/input/isic-pytorch-training-baseline-eva02/AUROC0.5177_Loss0.2829_epoch7.bin\n# !mv submission.csv submission_eva02.csv\n# # motono0223 2\n!python /kaggle/input/isic-script-inference-effnetv1b0-f313ae/main.py /kaggle/input/isic-pytorch-training-baseline-image-only/AUROC0.5171_Loss0.3476_epoch35.bin\n!mv submission.csv submission_effnetv1b0.csv\n# # Sinan Calisir\n!python /kaggle/input/isic-2024-pl-submission-script-and-preds/pl_submission.py\n!mv submission.csv submission_image3.csv\n# EdgeNext\n# !python /kaggle/input/isic-script-inference-edgenext/main.py /kaggle/input/isic-pytorch-training-edgenext/Final_model.bin\n# !mv submission.csv submission_edgenext.csv\n\n# eva02\n# df_s_eva  = pd.read_csv(\"submission_eva02.csv\")\n# df_t_eva  = pd.read_csv(\"/kaggle/input/isic-inference-eva02-for-training-data/train_eva02.csv\")\n# df_train[\"target_1\"] = df_t_eva[\"target_eva02\"]\n# df_test [\"target_1\"] = df_s_eva[\"target\"]\n# effnetv1b0\ndf_s_eff  = pd.read_csv(\"submission_effnetv1b0.csv\")\ndf_t_eff  = pd.read_csv(\"/kaggle/input/isic-inference-effnetv1b0-for-training-data/train_effnetv1b0.csv\")\ndf_train[\"target_2\"] = df_t_eff[\"target_effnetv1b0\"]\ndf_test [\"target_2\"] = df_s_eff[\"target\"]\n# # Sinan Calisir\ndf_s_img3 = pd.read_csv(\"submission_image3.csv\")\ndf_t_img3 = pd.read_csv(\"/kaggle/input/isic-2024-pl-submission-script-and-preds/train_preds.csv\")\ndf_train[\"target_3\"] = df_t_img3[\"pred\"]\ndf_test [\"target_3\"] = df_s_img3[\"target\"]\n# EdgeNext\n# df_s_ednx = pd.read_csv(\"submission_edgenext.csv\")\n# df_t_ednx = pd.read_csv(\"/kaggle/input/isic-inference-edgenext-for-training-data/train_edgenext.csv\")\n# df_train[\"target_4\"] = df_t_ednx['target_edgenext']\n# df_test [\"target_4\"] = df_s_ednx['target']\n\n\n_ll_lines = [\"target_2\",\"target_3\"] # \"target_1\",\"target_4\"\n\nfeature_cols.extend(_ll_lines)\n\n# for col in [\"target_1\",\"target_4\",\"target_2\",\"target_3\"]:\n#     if col in feature_cols: feature_cols.remove(col)\n        \n# i =0\n# for col in feature_cols: \n#     print(f\"{i} {col}\")\n#     i += 1","metadata":{"papermill":{"duration":44.310513,"end_time":"2024-07-20T23:26:39.317429","exception":false,"start_time":"2024-07-20T23:25:55.006916","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Optuna HyperParam Tuned Models","metadata":{}},{"cell_type":"code","source":"lgb_params = {\n    'objective':        'binary',\n    'verbosity':        -1,\n    'n_iter':           200,\n    'boosting_type':    'gbdt',\n    'random_state':     seed,\n    'lambda_l1':        0.08758718919397321, \n    'lambda_l2':        0.0039689175176025465, \n    'learning_rate':    0.03231007103195577, \n    'max_depth':        4, \n    'num_leaves':       103, \n    'colsample_bytree': 0.8329551585827726, \n    'colsample_bynode': 0.4025961355653304, \n    'bagging_fraction': 0.7738954452473223, \n    'bagging_freq':     4, \n    'min_data_in_leaf': 85, \n    'scale_pos_weight': 2.7984184778875543,\n}\n\nlgb_model = Pipeline([\n    ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=seed)),\n    ('classifier', lgb.LGBMClassifier(**lgb_params)),\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-07T15:14:38.113468Z","iopub.execute_input":"2024-08-07T15:14:38.113905Z","iopub.status.idle":"2024-08-07T15:14:38.122661Z","shell.execute_reply.started":"2024-08-07T15:14:38.113869Z","shell.execute_reply":"2024-08-07T15:14:38.121161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb_params = {\n    'loss_function':     'Logloss',\n    'iterations':        200,\n    'verbose':           False,\n    'random_state':      seed,\n    'max_depth':         7, \n    'learning_rate':     0.06936242010150652, \n    'scale_pos_weight':  2.6149345838209532, \n    'l2_leaf_reg':       6.216113851699493, \n    'subsample':         0.6249261779711819, \n    'min_data_in_leaf':  24,\n    'cat_features':      cat_cols,\n}\n\ncb_model = Pipeline([\n    ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=seed)),\n    ('classifier', cb.CatBoostClassifier(**cb_params)),\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-07T15:14:41.523657Z","iopub.execute_input":"2024-08-07T15:14:41.52411Z","iopub.status.idle":"2024-08-07T15:14:41.535853Z","shell.execute_reply.started":"2024-08-07T15:14:41.524067Z","shell.execute_reply":"2024-08-07T15:14:41.534579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params = {\n    'enable_categorical': True,\n    'tree_method':        'hist',\n    'random_state':       seed,\n    'learning_rate':      0.08501257473292347, \n    'lambda':             8.879624125465703, \n    'alpha':              0.6779926606782505, \n    'max_depth':          6, \n    'subsample':          0.6012681388711075, \n    'colsample_bytree':   0.8437772277074493, \n    'colsample_bylevel':  0.5476090898823716, \n    'colsample_bynode':   0.9928601203635129, \n    'scale_pos_weight':   3.29440313334688,\n}\n\nxgb_model = Pipeline([\n    ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=seed)),\n    ('classifier', xgb.XGBClassifier(**xgb_params)),\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-07T15:14:45.270558Z","iopub.execute_input":"2024-08-07T15:14:45.270963Z","iopub.status.idle":"2024-08-07T15:14:45.278444Z","shell.execute_reply.started":"2024-08-07T15:14:45.270934Z","shell.execute_reply":"2024-08-07T15:14:45.277278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator = VotingClassifier([('lgb',lgb_model),('cb',cb_model),('xgb',xgb_model)], voting='soft')","metadata":{"execution":{"iopub.status.busy":"2024-08-07T15:14:48.405086Z","iopub.execute_input":"2024-08-07T15:14:48.405512Z","iopub.status.idle":"2024-08-07T15:14:48.411443Z","shell.execute_reply.started":"2024-08-07T15:14:48.405481Z","shell.execute_reply":"2024-08-07T15:14:48.410226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cross Validation","metadata":{}},{"cell_type":"code","source":"X = df_train[feature_cols]\ny = df_train[target_col]\ngroups = df_train[group_col]\ncv = StratifiedGroupKFold(5, shuffle=True, random_state=seed)\n\nval_score = cross_val_score(\n    estimator=estimator, \n    X=X, y=y, \n    cv=cv, \n    groups=groups,\n    scoring=custom_metric,\n)\n\nnp.mean(val_score), val_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Arhiv CV","metadata":{}},{"cell_type":"code","source":"# # eva02 + effnetv1b0 + Sinan Calisir + EdgeNext\n# (0.1711043893878197, array([0.16391746, 0.1705924 , 0.18563189, 0.16919838, 0.16618181])) = 0.17?\n\n# # effnetv1b0 + Sinan Calisir\n# (0.16936809170462103, array([0.1608367 , 0.17163082, 0.18456639, 0.16915739, 0.16064915]))\n\n# # eva02 + EdgeNext\n# (0.16936809170462103, array([0.1608367 , 0.17163082, 0.18456639, 0.16915739, 0.16064915]))\n\n# #\n# (0.17059215270746436, array([0.16298199, 0.17038208, 0.18342141, 0.17023452, 0.16594077])) = 0.178","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"X, y = df_train[feature_cols], df_train[target_col]\n\nestimator.fit(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction","metadata":{}},{"cell_type":"code","source":"df_subm['target'] = estimator.predict_proba(df_test[feature_cols])[:, 1]\n\ndf_subm.to_csv('submission.csv')\ndf_subm.head()","metadata":{},"execution_count":null,"outputs":[]}]}